

*You can find a detailled account of this internship in my [final report](./Rapport.pdf) (in french).*

---
TL;DR

2025 summer research internship under my [professor](https://www.lamsade.dauphine.fr/~ychevaleyre/)'s supervision. The original goal was to improve LLMs robustness in a roleplay setting. The subject changed quite a bit during the course of the summer and I ended up covering a broad spectrum of research topics related to instruction following. Namely LLM as judge, jailbreak attacks (both whitebox and blackbox), self-refinement and reward hacking. I ran the code from the paper [SPAR: self-play with tree-search refinement to improve instruction-following in large language models](https://arxiv.org/pdf/2412.11605) on the supercomputer [Jean Zay](http://www.idris.fr/jean-zay/jean-zay-presentation.html). I found that their original dataset was of poor quality and fixed it using the DeepSeek and ChatGPT's API. Toward the end, I focused on reward hacking but could not finish my work within the internship.







